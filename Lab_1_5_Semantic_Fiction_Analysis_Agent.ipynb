{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN93kfHY5h45S3TfhiAHsKB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/semral3021/SamralThesis/blob/main/Lab_1_5_Semantic_Fiction_Analysis_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Semantic Fiction Analysis Agent – End-to-End Demonstration (Lab 1.5)\n",
        "\n",
        "This notebook demonstrates my thesis-based AI system as an end-to-end AI agent using the Gemini API.\n",
        "\n",
        "The system takes a short fictional text (X) and produces a structured semantic interpretation (y).  \n",
        "It follows the pipeline described in my master thesis **\"Semantic Analysis of Works of Fiction\"**:\n",
        "\n",
        "- Data understanding (reading and parsing the scene)\n",
        "- Reasoning and inference (detecting themes, characters, emotions, narrative function)\n",
        "- Output generation (structured JSON-like result)\n"
      ],
      "metadata": {
        "id": "PYC595yVriIE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notebook Structure\n",
        "\n",
        "1. System overview (thesis-based AI agent)\n",
        "2. Gemini API setup (secure key loading)\n",
        "3. Loading prompt examples (zero-shot and few-shot)\n",
        "4. Running the zero-shot prompt (X → y)\n",
        "5. Running the few-shot prompt (X → y with examples)\n",
        "6. Explanation of the end-to-end pipeline\n",
        "7. Reflection on the results (Lab 1.5)\n"
      ],
      "metadata": {
        "id": "Hl_ACSooronJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U google-genai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmz53vOJzJee",
        "outputId": "e4bd2cd5-9cd6-4218-ae44-f4793d266634"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-genai in /usr/local/lib/python3.12/dist-packages (1.52.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.11.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.43.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai) (9.1.2)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.genai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "client = genai.Client(api_key=userdata.get(\"GEMINI_KEY\"))\n"
      ],
      "metadata": {
        "id": "AAtVpPI-zNqu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GEMINI_KEY = userdata.get(\"GEMINI_KEY\")\n",
        "print(\"API key loaded?\", GEMINI_KEY is not None)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de8GJcEnziVF",
        "outputId": "9320eda1-a237-40c3-dfa3-09cb0d9ff9ee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API key loaded? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.genai as genai\n",
        "\n",
        "client = genai.Client(api_key=GEMINI_KEY)\n",
        "\n",
        "print(\"Gemini client initialized.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeP8jcVhzlHG",
        "outputId": "0837944c-a35d-41f9-d3ee-2b9b6a2fbc2e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini client initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = client.models.list()\n",
        "for m in models:\n",
        "    print(m.name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbTVeRp_z89r",
        "outputId": "37fc5811-47f1-45cc-b4c1-76067c12b5ca"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/embedding-gecko-001\n",
            "models/gemini-2.5-pro-preview-03-25\n",
            "models/gemini-2.5-flash\n",
            "models/gemini-2.5-pro-preview-05-06\n",
            "models/gemini-2.5-pro-preview-06-05\n",
            "models/gemini-2.5-pro\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-2.0-pro-exp\n",
            "models/gemini-2.0-pro-exp-02-05\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.0-flash-thinking-exp-01-21\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/gemini-2.5-flash-preview-tts\n",
            "models/gemini-2.5-pro-preview-tts\n",
            "models/learnlm-2.0-flash-experimental\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/gemma-3n-e4b-it\n",
            "models/gemma-3n-e2b-it\n",
            "models/gemini-flash-latest\n",
            "models/gemini-flash-lite-latest\n",
            "models/gemini-pro-latest\n",
            "models/gemini-2.5-flash-lite\n",
            "models/gemini-2.5-flash-image-preview\n",
            "models/gemini-2.5-flash-image\n",
            "models/gemini-2.5-flash-preview-09-2025\n",
            "models/gemini-2.5-flash-lite-preview-09-2025\n",
            "models/gemini-3-pro-preview\n",
            "models/gemini-3-pro-image-preview\n",
            "models/nano-banana-pro-preview\n",
            "models/gemini-robotics-er-1.5-preview\n",
            "models/gemini-2.5-computer-use-preview-10-2025\n",
            "models/embedding-001\n",
            "models/text-embedding-004\n",
            "models/gemini-embedding-exp-03-07\n",
            "models/gemini-embedding-exp\n",
            "models/gemini-embedding-001\n",
            "models/aqa\n",
            "models/imagen-4.0-generate-preview-06-06\n",
            "models/imagen-4.0-ultra-generate-preview-06-06\n",
            "models/imagen-4.0-generate-001\n",
            "models/imagen-4.0-ultra-generate-001\n",
            "models/imagen-4.0-fast-generate-001\n",
            "models/veo-2.0-generate-001\n",
            "models/veo-3.0-generate-001\n",
            "models/veo-3.0-fast-generate-001\n",
            "models/veo-3.1-generate-preview\n",
            "models/veo-3.1-fast-generate-preview\n",
            "models/gemini-2.0-flash-live-001\n",
            "models/gemini-live-2.5-flash-preview\n",
            "models/gemini-2.5-flash-live-preview\n",
            "models/gemini-2.5-flash-native-audio-latest\n",
            "models/gemini-2.5-flash-native-audio-preview-09-2025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_zero = client.models.generate_content(\n",
        "    model=\"models/gemini-2.5-flash\",\n",
        "    contents=zero_shot_prompt\n",
        ")\n",
        "\n",
        "print(response_zero.text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LirDPClj0eb_",
        "outputId": "4a69ddea-f3fe-4ff4-e6f5-d15a1fa55576"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "  \"characters\": [\n",
            "    \"Evelyn\",\n",
            "    \"Dr. Marcus\",\n",
            "    \"The Captain\"\n",
            "  ],\n",
            "  \"entities\": [\n",
            "    \"control room\",\n",
            "    \"alarms\",\n",
            "    \"mission protocol\"\n",
            "  ],\n",
            "  \"themes\": [\n",
            "    \"defiance\",\n",
            "    \"authority vs. autonomy\",\n",
            "    \"past trauma/regret\",\n",
            "    \"moral choice\",\n",
            "    \"crisis\",\n",
            "    \"complicity\"\n",
            "  ],\n",
            "  \"sentiment\": \"Tense and critical, with an underlying sense of determined refusal.\",\n",
            "  \"tone\": \"Urgent, confrontational, dramatic.\",\n",
            "  \"narrative_role\": \"Establishes a central conflict and reveals key character motivation (Evelyn's past trauma) during a crisis.\",\n",
            "  \"character_dynamics\": \"Evelyn directly defies The Captain's authority; Dr. Marcus is a complicit, avoidant observer.\",\n",
            "  \"keywords\": [\n",
            "    \"alarms\",\n",
            "    \"defiance\",\n",
            "    \"authority\",\n",
            "    \"protocol\",\n",
            "    \"blind obedience\",\n",
            "    \"regret\",\n",
            "    \"crisis\",\n",
            "    \"guilt\"\n",
            "  ]\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_few = client.models.generate_content(\n",
        "    model=\"models/gemini-2.5-flash\",\n",
        "    contents=few_shot_prompt\n",
        ")\n",
        "\n",
        "print(response_few.text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShgwRiq00osM",
        "outputId": "76496657-9cdb-445c-d401-4837a87966ed"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "  \"characters\": [\"Evelyn\", \"Dr. Marcus\", \"Captain\"],\n",
            "  \"entities\": [\"dim control room\", \"alarms\", \"mission protocol\"],\n",
            "  \"themes\": [\"defiance\", \"past trauma\", \"authority vs. autonomy\", \"failure\"],\n",
            "  \"sentiment\": \"negative\",\n",
            "  \"tone\": \"tense, defiant, urgent\",\n",
            "  \"narrative_role\": \"pivotal refusal, revelation of character motivation\",\n",
            "  \"character_dynamics\": \"Evelyn asserts autonomy against Captain's insistence; Dr. Marcus shows avoidance\",\n",
            "  \"keywords\": [\"alarms\", \"insisted\", \"refused\", \"obey blindly\", \"failing\"]\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## End-to-End System Explanation\n",
        "\n",
        "This notebook demonstrates the end-to-end behavior of my Semantic Fiction Analysis Agent.\n",
        "\n",
        "**Pipeline Stages:**\n",
        "\n",
        "1. **Input (X)**  \n",
        "   A fictional scene is provided as text.\n",
        "\n",
        "2. **Data Understanding**  \n",
        "   The Gemini model interprets characters, entities, events, tone, and context.\n",
        "\n",
        "3. **Reasoning & Inference**  \n",
        "   The model identifies:\n",
        "   - themes\n",
        "   - emotional tone\n",
        "   - narrative function\n",
        "   - relationships between characters and story elements\n",
        "\n",
        "4. **Output Generation (y)**  \n",
        "   The system produces a structured JSON-like semantic interpretation of the scene.\n",
        "\n",
        "This corresponds to the conceptual AI agent described in my thesis and designed in Lab 1.4.\n"
      ],
      "metadata": {
        "id": "KnBGqKBz0y8M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reflection\n",
        "\n",
        "In this lab, I demonstrated my thesis-based AI system as a fully operational end-to-end solution using the Gemini API.\n",
        "Both zero-shot and few-shot prompts successfully generated structured semantic interpretations.\n",
        "Few-shot prompting produced more consistent and context-rich outputs, confirming the usefulness of examples in guiding the model.\n",
        "\n",
        "The system follows the pipeline defined in my thesis: data understanding, semantic reasoning, inference, and output generation.\n",
        "Gemini simplifies this workflow by handling linguistic and narrative reasoning internally.\n",
        "The main challenge was configuring the correct model versions, but once resolved, the agent functioned smoothly.\n",
        "\n",
        "Future improvements could include automating evaluation metrics, integrating larger fictional datasets, or creating a GUI for interactive use.\n"
      ],
      "metadata": {
        "id": "GrPUcirE06aX"
      }
    }
  ]
}